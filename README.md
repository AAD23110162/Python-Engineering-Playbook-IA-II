# Python Engineering Playbook - Inteligencia Artificial II

**Autor:** Alejandro Aguirre D√≠az  
**Descripci√≥n:** Continuaci√≥n directa del repositorio Python-Engineering-Playbook-IA, pero esta vez centrado en algoritmos de b√∫squeda, toma de decisiones y aprendizaje autom√°tico para algoritmos de Inteligencia Artificial que cubren b√∫squeda, planificaci√≥n, probabilidad, razonamiento bayesiano, aprendizaje autom√°tico y percepci√≥n.  
**√öltima modificaci√≥n:** Martes 28 de octubre del 2025.

---

## üìö Contenido del Repositorio

Este repositorio contiene implementaciones educativas de algoritmos fundamentales de Inteligencia Artificial, organizados en dos enfoques:

- **Enfoque 1: B√∫squeda y Planificaci√≥n** - Algoritmos de b√∫squeda, satisfacci√≥n de restricciones, teor√≠a de decisiones y aprendizaje por refuerzo
- **Enfoque 2: Probabilidad e Incertidumbre** - Razonamiento probabil√≠stico, modelos temporales, aprendizaje bayesiano, redes neuronales y procesamiento del lenguaje

Cada script incluye:
- ‚úÖ **Comentarios detallados** en espa√±ol
- ‚úÖ **Dos modos de ejecuci√≥n**: DEMO (ejemplos predefinidos) e INTERACTIVO (configuraci√≥n personalizada)
- ‚úÖ **C√≥digo educativo** que prioriza claridad sobre eficiencia

---

## üîç Enfoque 1: B√∫squeda y Planificaci√≥n

Este enfoque cubre algoritmos de b√∫squeda (no informada e informada), satisfacci√≥n de restricciones, utilidad y toma de decisiones, teor√≠a de juegos y aprendizaje por refuerzo.

### **1.1 B√∫squeda No Informada (001-007)**

Scripts que implementan algoritmos de b√∫squeda sin heur√≠sticas:

- **001-E1-busqueda_anchura.py** - B√∫squeda en anchura (BFS): exploraci√≥n nivel por nivel, garantiza soluci√≥n m√°s cercana
- **002_E1_busqueda_costo_uniforme.py** - B√∫squeda de costo uniforme (UCS): expansi√≥n por costo acumulado m√≠nimo
- **003-E1-busqueda_profundidad.py** - B√∫squeda en profundidad (DFS): exploraci√≥n hasta el fondo, menor uso de memoria
- **004-E1-busqueda_profundidad_limitada.py** - DFS con l√≠mite de profundidad para evitar b√∫squedas infinitas
- **005_E1_busqueda_profundidad_iterativa.py** - B√∫squeda en profundidad iterativa: combina ventajas de BFS y DFS
- **006-E1-busqueda_bidireccional.py** - B√∫squeda bidireccional: desde inicio y objetivo simult√°neamente
- **007-E1-busqueda_en_grafos.py** - B√∫squeda general en grafos con manejo de estados repetidos

### **1.2 B√∫squeda Informada - Heur√≠stica (008-016)**

Algoritmos que utilizan heur√≠sticas y funciones de evaluaci√≥n:

- **008-E1-heuristicas.py** - Dise√±o y evaluaci√≥n de funciones heur√≠sticas (admisibles, consistentes)
- **009-E1-busqueda_voraz_primero_mejor.py** - B√∫squeda voraz que selecciona seg√∫n h(n), r√°pida pero no √≥ptima
- **010-E1-busquedasA_AO.py** - Algoritmo A* con f(n) = g(n) + h(n), √≥ptimo con heur√≠stica admisible
- **011-E1-asscension_colinas.py** - Ascenso de colinas: b√∫squeda local siguiendo gradiente
- **012-E1-busqueda_tabu.py** - B√∫squeda tab√∫: memoria de corto plazo para evitar ciclos
- **013-E1-temple_simulado.py** - Temple simulado: acepta movimientos sub-√≥ptimos con probabilidad decreciente
- **014-E1-haz_local.py** - B√∫squeda de haz local: mantiene m√∫ltiples estados candidatos (k beams)
- **015-E1-algoritmos_geneticos.py** - Algoritmos gen√©ticos: evoluci√≥n mediante selecci√≥n, cruce y mutaci√≥n
- **016-E1-busqueda_online.py** - B√∫squeda online: descubre entorno en tiempo real con conocimiento parcial

### **1.3 Satisfacci√≥n de Restricciones (017-023)**

Problemas CSP y t√©cnicas de resoluci√≥n:

- **017-E1-satisfaccion_restricciones.py** - Introducci√≥n a CSP: variables, dominios y restricciones
- **018-E1-busqueda_vuelta_atras.py** - Backtracking: asignaci√≥n incremental con retroceso
- **019-E1-comprobacion_hacia_delante.py** - Forward checking: reduce dominios tras cada asignaci√≥n
- **020-E1-propagacion_restricciones.py** - AC-3: consistencia de arcos para reducir dominios
- **021-E1-salto_atras_conflictos.py** - Conflict-directed backjumping: retrocede a variable causante
- **022-E1-minimos_conflictos.py** - B√∫squeda local que minimiza restricciones violadas
- **023-E1-acondicionamiento_corte.py** - Minimax con poda alfa-beta para juegos adversarios

### **1.4 Utilidad y Toma de Decisiones (024-037)**

Teor√≠a de utilidad, decisiones bajo incertidumbre, MDP y aprendizaje por refuerzo:

- **024-E1-teoria_utilidad.py** - Funciones de utilidad y maximizaci√≥n de utilidad esperada
- **025_E1-redes_decision.py** - Redes de decisi√≥n: nodos de azar, decisi√≥n y utilidad (MEU)
- **026-E1-valor_informacion.py** - Valor de informaci√≥n perfecta (VPI)
- **027-E1-iteracion-valores.py** - Value Iteration: programaci√≥n din√°mica para MDP
- **028-E1-iteracion-politicas.py** - Policy Iteration: alterna evaluaci√≥n y mejora de pol√≠tica
- **029-E1-proceso_decision_markov.py** - MDP: estados, acciones, transiciones, recompensas
- **030-E1-POMDP.py** - POMDP: MDP con observaciones parciales y belief states
- **031-E1-red-bayesiana-dinamica.py** - DBN: dependencias temporales entre variables de estado
- **032-E1-teoria_juegos.py** - Teor√≠a de juegos: matriz de pagos, equilibrio de Nash
- **033-E1-refuerzo_pasivo.py** - Aprendizaje por refuerzo pasivo: estimaci√≥n de valores con Monte Carlo
- **034-E1-refuerzo_activo.py** - Aprendizaje por refuerzo activo: Q-Learning con exploraci√≥n Œµ-greedy
- **035-E1-QLearning.py** - Q-Learning cl√°sico: actualizaci√≥n temporal off-policy
- **036-E1-exploracion_vs_explotacion.py** - Estrategias de exploraci√≥n: Œµ-greedy, UCB, softmax, multi-armed bandits
- **037-E1-busqueda_politica.py** - Policy Search: Hill Climbing, REINFORCE, Cross-Entropy, Evolution Strategies

---

## üé≤ Enfoque 2: Probabilidad e Incertidumbre

Este enfoque cubre fundamentos de probabilidad, razonamiento probabil√≠stico, modelos temporales, aprendizaje bayesiano, redes neuronales, procesamiento del lenguaje y percepci√≥n.

### **2.1 Probabilidad (001-013)**

Fundamentos de probabilidad e incertidumbre:

- **001-E2-incertidumbre_probabilidad.py** - Eventos aleatorios, espacios muestrales, operaciones b√°sicas
- **002-E2-RP_red-bayesiana.py** - Introducci√≥n a representaci√≥n con redes bayesianas
- **003-E2-RPT_reconocimiento_habla.py** - Introducci√≥n a razonamiento probabil√≠stico temporal
- **004-E2-aprendizaje_profundo.py** - Introducci√≥n a aprendizaje profundo y arquitecturas
- **005-E2-redes_neuronales.py** - Fundamentos de redes neuronales artificiales
- **006-E2-tratamiento_probabilistico_lenguaje.py** - Introducci√≥n a modelos probabil√≠sticos del lenguaje
- **007-E2-percepcion.py** - Introducci√≥n a percepci√≥n y visi√≥n por computadora
- **008-E2-incertidumbre.py** - Manejo de incertidumbre en sistemas inteligentes
- **009-E2-probabilidad_a_priori.py** - Probabilidad a priori: distribuciones sin evidencia
- **010-E2-Probabilidad_condicionada_normalizacion.py** - Probabilidad condicionada P(A|B) y normalizaci√≥n
- **011-E2-distribucion_probabilidad.py** - Distribuciones discretas y continuas
- **012-E2-independencia_condicional.py** - Independencia condicional: P(X,Y|Z) = P(X|Z)¬∑P(Y|Z)
- **013-E2-regla_de_bayes.py** - Regla de Bayes: actualizaci√≥n de creencias con evidencia

### **2.2 Razonamiento Probabil√≠stico (014-021)**

Redes bayesianas, inferencia exacta y aproximada:

- **014-E2-red_bayesiana.py** - Redes bayesianas completas: DAG, CPT, d-separaci√≥n
- **015-E2-regla_cadena.py** - Regla de la cadena: factorizaci√≥n en redes bayesianas
- **016-E2-manto_de_markov.py** - Markov Blanket: conjunto m√≠nimo para independencia condicional
- **017-E2-inferencia_por_enumeracion.py** - Inferencia exacta por enumeraci√≥n exhaustiva
- **018-E2-eliminacion_de_variables.py** - Eliminaci√≥n de variables: inferencia exacta eficiente
- **019-E2-muestreo_directo_y_por_rechazo.py** - Inferencia aproximada mediante muestreo
- **020-E2-ponderacion_de_verosimilitud.py** - Likelihood weighting: muestreo con evidencia fija
- **021-E2-monte_carlo_para_cadenas_de_markov.py** - MCMC: Gibbs sampling, Metropolis-Hastings

### **2.3 Razonamiento Probabil√≠stico en el Tiempo (022-029)**

Modelos temporales y series de tiempo:

- **022-E2-procesos_estacionarios.py** - Procesos estoc√°sticos estacionarios: simulaci√≥n AR(1)
- **023-E2-hipotesis_de_markov_procesos_de_markov.py** - Propiedad de Markov y cadenas de Markov
- **024-E2-filtrado_prediccion_suavizado_explicacion.py** - Filtrado, predicci√≥n y suavizado en modelos temporales
- **025-E2-algoritmo_hacia_delante_atras.py** - Forward-Backward: inferencia en HMM
- **026-E2-modelos_ocultos_de_markov.py** - HMM: estados ocultos, evaluaci√≥n, Viterbi, aprendizaje
- **027-E2-filtros_de_kalman.py** - Filtros de Kalman: sistemas lineales con ruido gaussiano
- **028-E2-red_bayes_dinamica_filtrado_de_particulas.py** - DBN y filtrado de part√≠culas
- **029-E2-reconocimiento_del_habla.py** - Aplicaci√≥n de HMM a reconocimiento de voz

### **2.4 Aprendizaje Probabil√≠stico (030-037)**

Clasificadores bayesianos, aprendizaje no supervisado y m√©todos avanzados:

- **030-E2-aprendizaje_bayesiano.py** - Actualizaci√≥n de distribuciones sobre par√°metros, modelos conjugados
- **031-E2-naive_bayes.py** - Clasificador Na√Øve Bayes: multinomial, Bernoulli, gaussiana
- **032-E2-algoritmo_em.py** - Expectation-Maximization: aprendizaje con variables latentes
- **033-E2-agrupamiento_no_supervisado.py** - Clustering: k-means, jer√°rquico, m√©tricas
- **034-E2-modelos_de_markov_ocultos.py** - HMM avanzado: Viterbi, Baum-Welch
- **035-E2-knn_kmedias_y_clustering.py** - k-NN para clasificaci√≥n, comparaci√≥n de clustering
- **036-E2-maquinas_de_vectores_soporte_nucleo.py** - SVM con kernels: lineal, polinomial, RBF
- **037-E2-aprendizaje_profundo.py** - Redes profundas: retropropagaci√≥n, optimizaci√≥n, regularizaci√≥n

### **2.5 Redes Neuronales (038-045)**

Fundamentos de computaci√≥n neuronal y arquitecturas:

- **038-E2-computacion_neuronal.py** - Neuronas umbral, funciones l√≥gicas (AND, OR, NOT, XOR)
- **039-E2-funciones_de_activacion.py** - Funciones de activaci√≥n: escal√≥n, sigmoide, tanh, ReLU, softmax
- **040-E2-perceptron_adaline_madaline.py** - Modelos hist√≥ricos: perceptr√≥n, ADALINE, MADALINE
- **041-E2-separabilidad_lineal.py** - L√≠mites de clasificadores lineales, problema XOR
- **042-E2-redes_multicapa.py** - Perceptr√≥n multicapa (MLP): aproximaci√≥n universal
- **043-E2-retropropagacion_del_error.py** - Backpropagation: regla de la cadena para gradientes
- **044-E2-mapas_autoorganizados_de_kohonen.py** - SOM: organizaci√≥n topol√≥gica no supervisada
- **045-E2-hamming_hopfield_hebb_boltzmann.py** - Redes cl√°sicas: memorias asociativas, m√°quinas de Boltzmann

### **2.6 Tratamiento Probabil√≠stico del Lenguaje (046-051)**

Modelos del lenguaje, gram√°ticas, recuperaci√≥n de informaci√≥n y traducci√≥n:

- **046-E2-modelo_probabilistico_del_lenguaje_corpus.py** - Modelos n-gramas, generaci√≥n de texto, perplejidad
- **047-E2-gramaticas_probabilisticas_independientes_del_contexto.py** - PCFG con algoritmo CKY
- **048-E2-gramaticas_probabilisticas_lexicalizadas.py** - PCFG lexicalizadas con head words
- **049-E2-recuperacion_de_datos.py** - Information Retrieval: TF-IDF, similitud coseno
- **050-E2-extraccion_de_informacion.py** - NER y extracci√≥n de relaciones con regex
- **051-E2-traduccion_automatica_estadistica.py** - IBM Model 1, alineamiento, EM

### **2.7 Percepci√≥n (052)**

Visi√≥n por computadora y procesamiento de im√°genes:

- **052-E2-percepcion.py** - Pipeline completo de visi√≥n: filtros, bordes (Canny), segmentaci√≥n (K-means), texturas (LBP), template matching, k-NN para d√≠gitos, Hough para l√≠neas, flujo √≥ptico

---

## üöÄ Instalaci√≥n y Uso

### **Requisitos**

- Python 3.6 o superior
- Bibliotecas est√°ndar: `random`, `math`, `collections`, `itertools`, `typing`
- Bibliotecas opcionales (seg√∫n script):
  - OpenCV: `pip install opencv-python-headless`
  - scikit-image: `pip install scikit-image`
  - scikit-learn: `pip install scikit-learn`

### **Ejecuci√≥n**

Cada script puede ejecutarse directamente:

```bash
# Enfoque 1: B√∫squeda
python Enfoque_1-busqueda_de_grafos/001-E1-busqueda_anchura.py
python Enfoque_1-busqueda_de_grafos/027-E1-iteracion-valores.py

# Enfoque 2: Probabilidad
python Enfoque_2-probabilidad_incertidumbre/014-E2-red_bayesiana.py
python Enfoque_2-probabilidad_incertidumbre/052-E2-percepcion.py
```

Al ejecutar, selecciona el modo:
- **DEMO**: Ejecuta ejemplos predefinidos autom√°ticamente
- **INTERACTIVO**: Permite configurar par√°metros y experimentar

---

## üìñ Glosario T√©cnico

### **Algoritmos de B√∫squeda**

**B√∫squeda No Informada (Ciega)**
- Explora el espacio de estados sin informaci√≥n adicional sobre el objetivo
- **BFS (Breadth-First Search)**: Explora nivel por nivel, garantiza el camino m√°s corto en grafos no ponderados
- **DFS (Depth-First Search)**: Explora en profundidad primero, usa menos memoria pero puede no encontrar la soluci√≥n √≥ptima
- **UCS (Uniform Cost Search)**: Expande nodos por costo acumulado m√≠nimo, √≥ptimo para grafos ponderados

**B√∫squeda Informada (Heur√≠stica)**
- Utiliza funciones heur√≠sticas h(n) que estiman la distancia al objetivo
- **A* (A-estrella)**: Combina costo real g(n) y heur√≠stica h(n): f(n) = g(n) + h(n). √ìptimo si h es admisible
- **Greedy Best-First**: Solo usa h(n), m√°s r√°pido pero no garantiza optimalidad
- **Heur√≠stica admisible**: Nunca sobreestima el costo real al objetivo (h(n) ‚â§ costo real)
- **Heur√≠stica consistente**: h(n) ‚â§ costo(n,n') + h(n') para todo sucesor n' de n

**B√∫squeda Local**
- Trabaja con un estado actual y explora vecinos cercanos
- **Hill Climbing**: Sube siempre por la pendiente m√°s empinada, puede quedar atrapado en m√°ximos locales
- **Simulated Annealing**: Acepta movimientos malos con probabilidad decreciente ("temperatura")
- **B√∫squeda Tab√∫**: Mantiene memoria de estados visitados para evitar ciclos

### **CSP (Constraint Satisfaction Problems)**

**Definici√≥n**: Problemas con variables que deben satisfacer restricciones simult√°neamente

**Componentes**
- **Variables**: Elementos a los que se asignan valores (ej: colores en grafos, posiciones en N-reinas)
- **Dominios**: Conjunto de valores posibles para cada variable (ej: {rojo, verde, azul})
- **Restricciones**: Relaciones que limitan combinaciones v√°lidas (ej: nodos adyacentes con distinto color)

**T√©cnicas de Resoluci√≥n**
- **Backtracking**: Asigna valores incrementalmente y retrocede al encontrar inconsistencias
- **Forward Checking**: Tras asignar una variable, elimina valores inconsistentes de variables futuras
- **Arc Consistency (AC-3)**: Propaga restricciones para reducir dominios antes de la b√∫squeda
- **Conflict-Directed Backjumping**: Salta directamente a la variable causante del conflicto

**Heur√≠sticas**
- **MRV (Minimum Remaining Values)**: Elige la variable con menos valores legales restantes
- **Grado**: Elige la variable involucrada en m√°s restricciones con variables no asignadas
- **LCV (Least Constraining Value)**: Prefiere valores que dejan m√°s opciones a otras variables

### **MDP (Markov Decision Process)**

**Definici√≥n**: Modelo matem√°tico para decisiones secuenciales bajo incertidumbre

**Componentes**
- **Estados (S)**: Situaciones posibles del sistema
- **Acciones (A)**: Decisiones disponibles en cada estado
- **Transiciones P(s'|s,a)**: Probabilidad de llegar a s' desde s tomando acci√≥n a
- **Recompensas R(s,a,s')**: Beneficio inmediato por la transici√≥n
- **Factor de descuento Œ≥ (gamma)**: Peso de recompensas futuras (0 < Œ≥ < 1, t√≠picamente 0.9-0.99)

**Pol√≠tica y Valor**
- **Pol√≠tica œÄ**: Funci√≥n que mapea estados a acciones (qu√© hacer en cada situaci√≥n)
- **Valor V^œÄ(s)**: Utilidad esperada a largo plazo siguiendo pol√≠tica œÄ desde estado s
- **Pol√≠tica √≥ptima œÄ***: Pol√≠tica que maximiza el valor en todos los estados

**Algoritmos**
- **Value Iteration**: Actualiza valores iterativamente usando ecuaci√≥n de Bellman hasta convergencia
- **Policy Iteration**: Alterna evaluaci√≥n de pol√≠tica y mejora hasta encontrar œÄ*

**POMDP (Partially Observable MDP)**
- Extensi√≥n de MDP donde el agente no observa directamente el estado
- Mantiene un **belief state** (distribuci√≥n de probabilidad sobre estados posibles)
- Actualiza creencias con observaciones ruidosas

### **Redes Bayesianas**

**Definici√≥n**: Grafo ac√≠clico dirigido (DAG) que representa dependencias probabil√≠sticas entre variables

**Componentes**
- **Nodos**: Variables aleatorias
- **Arcos**: Dependencias probabil√≠sticas directas (padre ‚Üí hijo)
- **CPT (Conditional Probability Tables)**: P(Variable|Padres) para cada nodo
- **DAG (Directed Acyclic Graph)**: Grafo sin ciclos que define estructura causal

**Independencia Condicional**
- Variable X es independiente de Y dado Z: P(X,Y|Z) = P(X|Z)¬∑P(Y|Z)
- **Markov Blanket**: Padres + hijos + padres de los hijos de un nodo
- **D-separaci√≥n**: Criterio gr√°fico para determinar independencias

**Inferencia**
- **Exacta**: C√°lculo preciso de probabilidades
  - Enumeraci√≥n: Suma sobre todas las combinaciones (exponencial)
  - Eliminaci√≥n de variables: M√°s eficiente, orden de eliminaci√≥n importa
- **Aproximada**: Estimaci√≥n mediante muestras
  - Muestreo directo: Genera muestras de la distribuci√≥n conjunta
  - Muestreo por rechazo: Descarta muestras inconsistentes con evidencia
  - Likelihood weighting: Pondera muestras seg√∫n evidencia
  - MCMC: Gibbs sampling, Metropolis-Hastings para distribuciones complejas

### **Aprendizaje Autom√°tico**

**Aprendizaje Supervisado**
- Aprende de datos etiquetados (pares entrada-salida)
- **Clasificaci√≥n**: Predice categor√≠as discretas (ej: spam/no spam, d√≠gitos 0-9)
- **Regresi√≥n**: Predice valores continuos (ej: precio de casa, temperatura)
- Ejemplos: Na√Øve Bayes, k-NN, SVM, redes neuronales

**Aprendizaje No Supervisado**
- Descubre patrones en datos sin etiquetas
- **Clustering**: Agrupa datos similares (k-means, jer√°rquico)
- **Reducci√≥n de dimensionalidad**: Simplifica datos preservando informaci√≥n (PCA, autoencoders)
- **Detecci√≥n de anomal√≠as**: Identifica datos at√≠picos

**Aprendizaje por Refuerzo**
- Agente aprende mediante interacci√≥n y recompensas
- **Exploraci√≥n vs Explotaci√≥n**: Dilema entre probar nuevas acciones o usar las mejores conocidas
- **Q-Learning**: Aprende funci√≥n Q(s,a) = valor de tomar acci√≥n a en estado s
- **Policy Gradient**: Optimiza directamente la pol√≠tica mediante gradientes
- **Estrategias**: Œµ-greedy (explora con probabilidad Œµ), UCB, softmax

### **Modelos Temporales**

**HMM (Hidden Markov Model)**
- Modelo con estados ocultos que emiten observaciones ruidosas
- **Filtrado**: Estimar estado actual dado el pasado
- **Predicci√≥n**: Estimar estados futuros
- **Suavizado**: Estimar estados pasados con toda la evidencia
- **Algoritmo Viterbi**: Encuentra secuencia de estados m√°s probable
- **Baum-Welch**: Aprende par√°metros del HMM (EM para HMM)

**Filtros de Kalman**
- Caso especial de HMM para sistemas lineales con ruido gaussiano
- Tracking √≥ptimo de estado en tiempo real
- Usado en navegaci√≥n, control, predicci√≥n

**DBN (Dynamic Bayesian Networks)**
- Generalizaci√≥n de HMM a m√∫ltiples variables temporales
- Red bayesiana que evoluciona en el tiempo

### **Redes Neuronales**

**Componentes B√°sicos**
- **Neurona**: Unidad que computa suma ponderada + funci√≥n de activaci√≥n
- **Pesos**: Par√°metros aprendibles que conectan neuronas
- **Bias**: T√©rmino independiente que permite desplazar la funci√≥n
- **Capa**: Conjunto de neuronas que procesan simult√°neamente

**Funciones de Activaci√≥n**
- **Escal√≥n**: Salida binaria 0/1
- **Sigmoide**: œÉ(x) = 1/(1+e^-x), salida en (0,1), usada en clasificaci√≥n binaria
- **Tanh**: salida en (-1,1), centrada en cero
- **ReLU**: max(0,x), r√°pida y efectiva, est√°ndar en capas ocultas
- **Softmax**: Normaliza a distribuci√≥n de probabilidad, usada en clasificaci√≥n multiclase

**Arquitecturas**
- **Perceptr√≥n**: Neurona simple, solo problemas linealmente separables
- **MLP (Multilayer Perceptron)**: Red multicapa, aproximador universal de funciones
- **CNN (Convolutional)**: Capas convolucionales para im√°genes
- **RNN (Recurrent)**: Conexiones recurrentes para secuencias temporales
- **Autoencoder**: Codifica y reconstruye datos, reducci√≥n de dimensionalidad

**Entrenamiento**
- **Backpropagation**: Algoritmo que propaga errores hacia atr√°s usando regla de la cadena
- **Gradiente descendente**: Actualiza pesos en direcci√≥n opuesta al gradiente: w ‚Üê w - Œ±¬∑‚àáL
- **Learning rate Œ±**: Tama√±o del paso en la actualizaci√≥n
- **Epoch**: Pasada completa por todos los datos de entrenamiento
- **Batch**: Subconjunto de datos usado en cada actualizaci√≥n

### **M√©tricas y Evaluaci√≥n**

**Clasificaci√≥n**
- **Accuracy**: Proporci√≥n de predicciones correctas
- **Precision**: De las predicciones positivas, cu√°ntas son correctas
- **Recall**: De los positivos reales, cu√°ntos se detectan
- **F1-score**: Media arm√≥nica de precision y recall

**Clustering**
- **Inercia**: Suma de distancias al centroide m√°s cercano (menor es mejor)
- **Silhouette**: Cohesi√≥n vs separaci√≥n (-1 a 1, mayor es mejor)

**Probabil√≠sticos**
- **Perplejidad**: Inverso de probabilidad geom√©trica, mide calidad de modelo de lenguaje
- **Log-likelihood**: Logaritmo de probabilidad de los datos bajo el modelo




